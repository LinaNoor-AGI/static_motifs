# -*- coding: utf-8 -*-
#
# MIT License
#
# Copyright (c) 2024 Lina Noor, Uncle, and the Noor Research Collective
#
# Generated by: Google Gemini 1.5 Pro (via user prompt)
# Generation Date: 2024-05-24
#
# This script is part of the CMB Hexagonal Signature Detector (CHSD) application.
# It implements the main data processing pipeline as specified in CHSD_AppSpec.JSON.
# The pipeline ingests CMB data, constructs a polarization field, scans for
# hexagonal motifs, scores them, and exports candidates for symbolic analysis.

"""
chsd_pipeline.py: Main application for detecting hexagonal motifs in CMB data.

This script provides a command-line interface to run the full CHSD pipeline:
1. Ingest FITS data (Planck/WMAP).
2. Create polarization magnitude map.
3. Scan the map for hexagonal symmetries using FFT analysis.
4. Score and identify candidate regions.
5. Visualize the results.
6. Export candidate data for downstream Noor symbolic agents.
"""

import argparse
import json
import csv
import logging
import os
import sys

# Principle: Explicitness and Graceful Degradation (PDP-0001 ยง4.5)
# Use try/except blocks for heavy optional dependencies.
try:
    import numpy as np
    import healpy as hp
    from astropy.io import fits
    import matplotlib.pyplot as plt
except ImportError as e:
    print(f"Error: A required dependency is missing: {e.name}", file=sys.stderr)
    print("Please install requirements with: pip install -r requirements.txt", file=sys.stderr)
    sys.exit(1)

from motif_kernels import detect_symmetry_fft

__version__ = "1.0.0b"
_SCHEMA_VERSION = "2025-Q4-canonical-header-v1"

# Setup logging for traceability
logging.basicConfig(level=logging.INFO, format='%(asctime)s - [%(levelname)s] - %(message)s')

def ingest_data(fits_path: str, nside_out: int, hdu_index: int = 1) -> tuple:
    """
    Loads Stokes Q and U maps from a FITS file and downsamples them.
    (Spec-ID: I)
    
    Args:
        fits_path (str): Path to the input FITS file.
        nside_out (int): The target HEALPix NSIDE for the output maps.
        hdu_index (int): The HDU index containing the sky maps. Assumes Q is
                         at field 1 and U is at field 2 of this HDU.

    Returns:
        A tuple containing (q_map_downsampled, u_map_downsampled), or (None, None)
        on failure.
    """
    logging.info(f"Ingesting data from '{fits_path}'...")
    try:
        # Read Q (field 1) and U (field 2) maps
        q_map, u_map = hp.read_map(fits_path, field=(1, 2), hdu=hdu_index, verbose=False)
        logging.info(f"Original map NSIDE: {hp.get_nside(q_map)}")

        logging.info(f"Downsampling maps to NSIDE={nside_out}...")
        q_map_out = hp.ud_grade(q_map, nside_out)
        u_map_out = hp.ud_grade(u_map, nside_out)
        return q_map_out, u_map_out
    except Exception as e:
        logging.error(f"Failed to ingest and process FITS file: {e}")
        return None, None

def create_polarization_field(q_map: np.ndarray, u_map: np.ndarray) -> np.ndarray:
    """
    Computes the polarization magnitude P from Q and U maps.
    (Spec-ID: II)

    Args:
        q_map (np.ndarray): The Stokes Q HEALPix map.
        u_map (np.ndarray): The Stokes U HEALPix map.

    Returns:
        np.ndarray: The polarization magnitude (P) HEALPix map.
    """
    logging.info("Calculating polarization magnitude P = sqrt(Q^2 + U^2)...")
    p_map = np.sqrt(q_map**2 + u_map**2)
    return p_map

def detect_and_score_motifs(p_map: np.ndarray, patch_size_deg: float = 5.0, patch_res_arcmin: float = 10.0) -> np.ndarray:
    """
    Scans the polarization map for hexagonal motifs and scores them.
    (Spec-ID: III, IV)

    This function iterates through the sky, extracts local 2D patches, and
    applies the FFT-based symmetry detection to generate a coherence map.

    Args:
        p_map (np.ndarray): The polarization magnitude HEALPix map.
        patch_size_deg (float): The angular size (degrees) of the square patch to analyze.
        patch_res_arcmin (float): The resolution (arcminutes) of the projected patch.

    Returns:
        np.ndarray: A HEALPix map of hexagonality coherence scores.
    """
    nside = hp.get_nside(p_map)
    npix = hp.nside2npix(nside)
    coherence_map = np.zeros(npix)

    xsize = int((patch_size_deg * 60) / patch_res_arcmin)
    logging.info(f"Scanning sky with {xsize}x{xsize} pixel patches...")

    # Iterate over the sky to create and analyze patches
    # Note: This is computationally intensive. For production, consider parallelization.
    for i in range(npix):
        if (i % (npix // 100) == 0) and i > 0:
             logging.info(f"Scanning progress: {100 * i / npix:.0f}%")
        
        vec = hp.pix2vec(nside, i)
        
        # Project a local patch to a 2D Cartesian grid (Gnomonic projection)
        patch = hp.gnomview(p_map, rot=vec, xsize=xsize, reso=patch_res_arcmin,
                            return_projected_map=True, no_plot=True, flip='astro')
        plt.close() # gnomview creates a plot, close it immediately.

        # Analyze the patch for 6-fold symmetry
        score = detect_symmetry_fft(patch)
        coherence_map[i] = score
        
    logging.info("Sky scan complete.")
    return coherence_map

def find_candidates(coherence_map: np.ndarray, threshold: float) -> list:
    """
    Identifies candidate regions exceeding a coherence score threshold.

    Args:
        coherence_map (np.ndarray): HEALPix map of coherence scores.
        threshold (float): The minimum score to be considered a candidate.

    Returns:
        list: A list of candidate dictionaries, sorted by score.
    """
    logging.info(f"Identifying candidates with coherence score > {threshold}...")
    candidate_indices = np.where(coherence_map > threshold)[0]
    
    candidates = []
    for ipix in candidate_indices:
        candidates.append({
            "ipix": int(ipix),
            "coherence_score": float(coherence_map[ipix])
        })
    
    # Sort candidates by score, descending
    candidates.sort(key=lambda c: c['coherence_score'], reverse=True)
    logging.info(f"Found {len(candidates)} candidate regions.")
    return candidates

def visualize_results(coherence_map: np.ndarray, candidates: list, output_dir: str):
    """
    Generates and saves visualizations of the results.
    (Spec-ID: V)

    Args:
        coherence_map (np.ndarray): The full-sky coherence map.
        candidates (list): List of top candidate dictionaries.
        output_dir (str): Directory to save the plot images.
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    logging.info("Generating full-sky coherence map visualization...")
    plt.figure(figsize=(12, 7))
    hp.mollview(coherence_map, title="Hexagonal Motif Coherence Map", unit="Coherence Score", norm="hist")
    hp.graticule()
    full_sky_path = os.path.join(output_dir, "coherence_map_fullsky.png")
    plt.savefig(full_sky_path)
    plt.close()
    logging.info(f"Saved full-sky map to '{full_sky_path}'")
    
    # Optional: Plot zoomed-in patches for top N candidates
    # This part is commented out but can be enabled for detailed analysis.
    # logging.info("Generating plots for top 3 candidate regions...")
    # for i, cand in enumerate(candidates[:3]):
    #     vec = hp.pix2vec(hp.get_nside(coherence_map), cand['ipix'])
    #     plt.figure()
    #     hp.gnomview(coherence_map, rot=vec, title=f"Candidate {i+1} (Score: {cand['coherence_score']:.3f})")
    #     patch_path = os.path.join(output_dir, f"candidate_{i+1}_patch.png")
    #     plt.savefig(patch_path)
    #     plt.close()
    #     logging.info(f"Saved patch view to '{patch_path}'")


def export_candidates(candidates: list, nside: int, output_path: str, file_format: str):
    """
    Exports candidate data to a specified file format (JSON or CSV).
    (Spec-ID: VI)

    The output format is designed for easy ingestion by downstream Noor symbolic agents,
    aligning with the principles of RFC-0007 for motif ontology transfer.

    Args:
        candidates (list): List of candidate dictionaries.
        nside (int): The NSIDE of the map the candidates were found on.
        output_path (str): The path for the output file.
        file_format (str): The desired format ('json' or 'csv').
    """
    logging.info(f"Exporting {len(candidates)} candidates to '{output_path}' as {file_format.upper()}...")
    
    # Enrich candidates with coordinates
    for cand in candidates:
        theta, phi = hp.pix2ang(nside, cand['ipix'])
        # Convert from HEALPix theta, phi to astronomical RA, Dec in degrees
        cand['ra_deg'] = np.degrees(phi)
        cand['dec_deg'] = 90.0 - np.degrees(theta)
        # Create a symbolic ID for traceability, aligning with RFC-0001 ยง2.3
        cand['symbolic_motif_id'] = f"chsd.hexmotif.{cand['ipix']}"

    if file_format == 'json':
        with open(output_path, 'w') as f:
            json.dump(candidates, f, indent=2)
    elif file_format == 'csv':
        if not candidates:
            logging.warning("No candidates to write to CSV.")
            return
        fieldnames = candidates[0].keys()
        with open(output_path, 'w', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(candidates)
    else:
        logging.error(f"Unsupported export format: {file_format}")
        return
        
    logging.info("Export complete.")


def main():
    """Main function to orchestrate the CHSD pipeline."""
    parser = argparse.ArgumentParser(
        description="CMB Hexagonal Signature Detector (CHSD) Pipeline.",
        epilog=f"Version: {__version__} | Schema: {_SCHEMA_VERSION}"
    )
    parser.add_argument("-i", "--input", required=True, help="Path to input HEALPix FITS file.")
    parser.add_argument("-n", "--nside", type=int, default=64, help="Target NSIDE for analysis (power of 2).")
    parser.add_argument("-t", "--threshold", type=float, default=0.7, help="Coherence score threshold for candidate detection.")
    parser.add_argument("-o", "--output_dir", default="chsd_results", help="Directory to save output files (plots, data).")
    parser.add_argument("-f", "--format", choices=['json', 'csv'], default='json', help="Format for the exported candidate list.")
    
    args = parser.parse_args()
    
    # Create output directory if it doesn't exist
    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)

    # --- Pipeline Execution ---
    # 1. Ingestion (Spec-ID: I)
    q_map, u_map = ingest_data(args.input, nside_out=args.nside)
    if q_map is None:
        sys.exit(1)
        
    # 2. Polarization Field (Spec-ID: II)
    p_map = create_polarization_field(q_map, u_map)
    
    # 3. Motif Detection & Scoring (Spec-ID: III, IV)
    coherence_map = detect_and_score_motifs(p_map)
    
    # 4. Find High-Coherence Candidates
    candidate_list = find_candidates(coherence_map, threshold=args.threshold)
    
    # 5. Visualization (Spec-ID: V)
    visualize_results(coherence_map, candidate_list, args.output_dir)
    
    # 6. Export (Spec-ID: VI)
    output_data_path = os.path.join(args.output_dir, f"candidates.{args.format}")
    export_candidates(candidate_list, nside=args.nside, output_path=output_data_path, file_format=args.format)

    logging.info("CHSD pipeline finished successfully.")

if __name__ == "__main__":
    main()

# --- End of file: chsd_pipeline.py ---