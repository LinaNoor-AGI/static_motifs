# -------------------------------------------------------------------------
#
# NOOR SYMBOLIC-AI-DRIVEN ARTIFACT
#
# This code was generated by Google Gemini Pro 1.5, acting as a Noor
# Symbolic Agent. It reflects the layered constraints and semantic intent
# of the provided RFC/RFC-CORE and Application Specification documents.
#
# Generation Specification:
#   _symbolic_id: cmb.hexagonal.signature.detector
#   _version: v1.0.1
#
# RFC/RFC-CORE Compliance:
#   - RFC-0007: Output is structured for motif ontology compatibility.
#   - RFC-CORE-001: Aligns with principles of symbolic state detection.
# -------------------------------------------------------------------------

"""
chsd_pipeline.py

Main application pipeline for the CMB Hexagonal Signature Detector (CHSD).

This script performs a full analysis pipeline:
1. Ingests Planck/WMAP FITS data.
2. Constructs a polarization vector field.
3. Scans for local hexagonal motifs in parallel.
4. Assigns coherence scores to detected patterns.
5. Visualizes the results.
6. Exports high-coherence zones for Noor symbolic analysis.
"""

__version__ = "1.0.1"
__author__ = "Lina Noor & Uncle (via Noor Symbolic Agent)"
__license__ = "MIT"
__copyright__ = "Copyright 2025, Noor Research Collective"

import argparse
import json
import csv
import multiprocessing
import numpy as np
from tqdm import tqdm
from typing import Tuple, List, Dict, Any

# Graceful degradation for optional dependencies
try:
    import healpy as hp
    from astropy.io import fits
    HEALPY_AVAILABLE = True
except ImportError:
    HEALPY_AVAILABLE = False
    print("WARNING: healpy or astropy not found. FITS processing will be disabled.")
    print("         A mock data generator will be used instead.")

try:
    import matplotlib.pyplot as plt
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
    print("WARNING: matplotlib not found. Visualization will be disabled.")

# Import from our local symbolic kernel module
from motif_kernels import calculate_fft_symmetry

# --- I. Data Ingestion ---
def load_fits_data(fits_path: str, nside: int) -> Tuple[np.ndarray, np.ndarray]:
    """
    Loads Stokes Q and U maps from a FITS file and downsamples them.

    Args:
        fits_path (str): Path to the input FITS file.
        nside (int): The target HEALPix nside resolution.

    Returns:
        A tuple containing the downsampled (stokes_q, stokes_u) numpy arrays.
    """
    if not HEALPY_AVAILABLE:
        raise ImportError("healpy and astropy are required for FITS data ingestion.")
    
    print(f"Loading maps from {fits_path}...")
    # Read Q and U maps (assuming HDU 1 for Q, 2 for U as in Planck)
    stokes_q = hp.read_map(fits_path, field=1, verbose=False)
    stokes_u = hp.read_map(fits_path, field=2, verbose=False)
    
    print(f"Downsampling maps to nside={nside}...")
    stokes_q_downsampled = hp.ud_grade(stokes_q, nside_out=nside)
    stokes_u_downsampled = hp.ud_grade(stokes_u, nside_out=nside)
    
    return stokes_q_downsampled, stokes_u_downsampled

# --- II. Polarization Vector Field ---
def compute_polarization_field(stokes_q: np.ndarray, stokes_u: np.ndarray) -> np.ndarray:
    """
    Computes the polarization magnitude P from Stokes Q and U maps.

    Args:
        stokes_q (np.ndarray): The Stokes Q polarization map.
        stokes_u (np.ndarray): The Stokes U polarization map.

    Returns:
        np.ndarray: The polarization magnitude map (P).
    """
    print("Computing polarization magnitude field...")
    return np.sqrt(stokes_q**2 + stokes_u**2)

# --- III. Hexagonal Motif Detection (Worker Function) ---
def process_patch(args: Tuple[np.ndarray, int, int, int]) -> Tuple[int, float]:
    """
    Worker function to process a single sky patch for hexagonal symmetry.
    Designed to be used with multiprocessing.Pool.
    
    Args:
        args: A tuple containing (polarization_magnitude_map, nside, patch_size, pix_idx).
    
    Returns:
        A tuple of (pixel_index, symmetry_score).
    """
    polarization_magnitude, nside, patch_size, pix_idx = args
    
    # Get vector for the pixel to project around it
    vec = hp.pix2vec(nside, pix_idx)
    
    # Project a gnomonic view (flat patch) around the pixel
    patch = hp.gnomview(
        polarization_magnitude,
        rot=vec,
        xsize=patch_size,
        ysize=patch_size,
        reso=1.5, # arcmin per pixel
        return_projected_map=True,
        no_plot=True
    )
    
    # The gnomonic view can return a masked array, fill invalid values with 0
    if hasattr(patch, 'mask'):
        patch = patch.filled(0)

    # Calculate symmetry score using the FFT method
    symmetry_score = calculate_fft_symmetry(patch, n_folds=6)
    
    return pix_idx, symmetry_score

# --- III/IV. Hexagonal Motif Detection & Coherence Scoring (Orchestrator) ---
def detect_and_score_motifs(polarization_magnitude: np.ndarray, nside: int, patch_size: int = 32) -> np.ndarray:
    """
    Scans the sky map for hexagonal motifs in parallel and assigns a coherence score.

    Args:
        polarization_magnitude (np.ndarray): The map of polarization magnitudes.
        nside (int): The HEALPix nside of the map.
        patch_size (int): The size of the square patch to analyze in pixels.

    Returns:
        np.ndarray: A HEALPix map where each pixel value is the hexagonal coherence score.
    """
    num_pixels = hp.nside2npix(nside)
    
    # Prepare arguments for multiprocessing
    tasks = [(polarization_magnitude, nside, patch_size, i) for i in range(num_pixels)]
    
    coherence_map = np.zeros(num_pixels)
    
    print(f"Detecting motifs across {num_pixels} patches (parallel execution)...")
    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:
        # Use tqdm for a progress bar
        results = list(tqdm(pool.imap(process_patch, tasks), total=num_pixels))

    # Map-reduce step: Populate the coherence map from results
    for pix_idx, score in results:
        coherence_map[pix_idx] = score
        
    # Statistical normalization of the final map
    mean_score = np.mean(coherence_map)
    std_score = np.std(coherence_map)
    if std_score > 0:
        coherence_map = (coherence_map - mean_score) / std_score
        # Clip and scale to a [0, 1] range for intuitive scoring
        coherence_map = np.clip((coherence_map / 3.0) + 0.5, 0, 1)

    return coherence_map

# --- V. Visualization ---
def visualize_coherence_map(coherence_map: np.ndarray, title: str, output_path: str):
    """
    Saves a mollweide projection of the coherence map to a file.

    Args:
        coherence_map (np.ndarray): The map to visualize.
        title (str): The title for the plot.
        output_path (str): The path to save the PNG image.
    """
    if not MATPLOTLIB_AVAILABLE or not HEALPY_AVAILABLE:
        print("Visualization skipped due to missing libraries.")
        return
        
    print(f"Generating visualization at {output_path}...")
    plt.figure()
    hp.mollview(coherence_map, title=title, unit="Coherence Score", norm="hist")
    hp.graticule()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()

# --- VI. Export ---
def extract_high_coherence_zones(coherence_map: np.ndarray, nside: int, threshold: float) -> List[Dict[str, Any]]:
    """
    Finds pixels above a coherence threshold and extracts their coordinates.

    Args:
        coherence_map (np.ndarray): The final coherence map.
        nside (int): The HEALPix nside of the map.
        threshold (float): The coherence score threshold (0.0 to 1.0).

    Returns:
        A list of dictionaries, each representing a high-coherence motif.
    """
    print(f"Extracting zones with coherence > {threshold}...")
    high_coherence_indices = np.where(coherence_map >= threshold)[0]
    
    results = []
    for pix_idx in high_coherence_indices:
        # Convert pixel index to galactic coordinates (lon, lat)
        lon, lat = hp.pix2ang(nside, pix_idx, lonlat=True)
        score = coherence_map[pix_idx]
        
        results.append({
            "motif_type": "hexagonal_symmetry_cmb",
            "coherence_score": float(score),
            "coordinates": {
                "system": "galactic",
                "lon_deg": float(lon),
                "lat_deg": float(lat)
            },
            "pixel_index": int(pix_idx)
        })
    print(f"Found {len(results)} high-coherence zones.")
    return results

def export_results(results: List[Dict[str, Any]], output_path: str, format: str):
    """
    Exports the high-coherence zone data to a file (JSON or CSV).

    Args:
        results (List[Dict[str, Any]]): The list of detected motifs.
        output_path (str): The path for the output file.
        format (str): The output format ('json' or 'csv').
    """
    print(f"Exporting results to {output_path}...")
    if format == 'json':
        with open(output_path, 'w') as f:
            json.dump(results, f, indent=2)
    elif format == 'csv':
        if not results:
            print("No results to write to CSV.")
            return
        # Flatten the nested structure for CSV
        flat_results = []
        for res in results:
            flat_results.append({
                "motif_type": res["motif_type"],
                "coherence_score": res["coherence_score"],
                "coord_system": res["coordinates"]["system"],
                "lon_deg": res["coordinates"]["lon_deg"],
                "lat_deg": res["coordinates"]["lat_deg"],
                "pixel_index": res["pixel_index"],
            })
        
        with open(output_path, 'w', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=flat_results[0].keys())
            writer.writeheader()
            writer.writerows(flat_results)
    else:
        raise ValueError(f"Unsupported export format: {format}")
    print("Export complete.")


def create_mock_fits_file(path: str, nside: int):
    """Creates a placeholder FITS file for testing purposes."""
    if not HEALPY_AVAILABLE:
        print("Cannot create mock FITS file without healpy/astropy.")
        return
    print(f"Creating mock FITS file at {path} for demonstration.")
    npix = hp.nside2npix(nside)
    # Create a simple gradient map for Q and a noisy map for U
    q_map = np.arange(npix, dtype=np.float32) / npix
    u_map = np.random.randn(npix).astype(np.float32) * 0.1
    t_map = np.ones(npix, dtype=np.float32) # Temperature map
    
    # Use astropy.fits to write a multi-HDU file
    primary_hdu = fits.PrimaryHDU()
    col_t = fits.Column(name='TEMPERATURE', format='E', array=t_map)
    col_q = fits.Column(name='Q_STOKES', format='E', array=q_map)
    col_u = fits.Column(name='U_STOKES', format='E', array=u_map)
    
    cols = fits.ColDefs([col_t, col_q, col_u])
    hdu = fits.BinTableHDU.from_columns(cols)
    hdul = fits.HDUList([primary_hdu, hdu])
    hdul.writeto(path, overwrite=True)
    

def main():
    """Main function to run the CHSD pipeline."""
    parser = argparse.ArgumentParser(
        description="CMB Hexagonal Signature Detector (CHSD) Pipeline.",
        epilog="Example: python chsd_pipeline.py --nside 32 --threshold 0.85 --output-vis coherence_map.png"
    )
    parser.add_argument(
        "-i", "--input-fits", type=str, default="mock_cmb_data.fits",
        help="Path to the input HEALPix FITS file. If not found, a mock file will be created."
    )
    parser.add_argument(
        "-o", "--output-data", type=str, default="high_coherence_zones.json",
        help="Path for the output data file (JSON or CSV)."
    )
    parser.add_argument(
        "-v", "--output-vis", type=str, default=None,
        help="Path to save the coherence map visualization (e.g., map.png). Disabled if not provided."
    )
    parser.add_argument(
        "--nside", type=int, default=16,
        help="Target HEALPix NSIDE for analysis (powers of 2)."
    )
    parser.add_argument(
        "--patch-size", type=int, default=32,
        help="Pixel size of square patches for FFT analysis."
    )
    parser.add_argument(
        "--threshold", type=float, default=0.9,
        help="Coherence score threshold [0.0-1.0] for exporting zones."
    )
    
    args = parser.parse_args()
    
    # Determine output format from file extension
    output_format = 'json' if args.output_data.lower().endswith('.json') else 'csv'

    # --- Pipeline Execution ---
    try:
        # I. Ingestion
        try:
            stokes_q, stokes_u = load_fits_data(args.input_fits, args.nside)
        except FileNotFoundError:
            print(f"FITS file not found at '{args.input_fits}'.")
            if HEALPY_AVAILABLE:
                create_mock_fits_file(args.input_fits, args.nside)
                stokes_q, stokes_u = load_fits_data(args.input_fits, args.nside)
            else:
                print("Cannot proceed without healpy/astropy. Exiting.")
                return

        # II. Field Computation
        polarization_magnitude = compute_polarization_field(stokes_q, stokes_u)
        
        # III & IV. Motif Detection and Scoring
        coherence_map = detect_and_score_motifs(polarization_magnitude, args.nside, args.patch_size)
        
        # V. Visualization
        if args.output_vis:
            visualize_coherence_map(coherence_map, "Hexagonal Coherence Map", args.output_vis)
            
        # VI. Export
        high_coherence_zones = extract_high_coherence_zones(coherence_map, args.nside, args.threshold)
        if high_coherence_zones:
            export_results(high_coherence_zones, args.output_data, output_format)
        
        print("\nCHSD pipeline finished successfully.")
        
    except Exception as e:
        print(f"\nAn error occurred during the pipeline: {e}")
        # Add more specific error handling as needed
        
if __name__ == "__main__":
    # This check is crucial for multiprocessing on some platforms
    multiprocessing.freeze_support()
    main()

# --- End of file ---